{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/vol/bitbucket/jq619/individual-project/')\n",
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "from mgca.datasets.classification_dataset import RSNAImageDataset, COVIDXImageDataset\n",
    "from mgca.datasets.transforms import DataTransforms\n",
    "from models.adaptor import Adaptor, StreamingProgressBar\n",
    "from models.pipeline import AdaptorPipelineWithClassificationHead\n",
    "from models.configurations import TEXT_PRETRAINED, VISION_PRETRAINED\n",
    "from utils.model_utils import load_vision_model\n",
    "from utils.dataset_utils import torch2huggingface_dataset, get_dataloader\n",
    "\n",
    "from math import ceil\n",
    "import argparse \n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_model = 'resnet-ae'\n",
    "vision_model_config = VISION_PRETRAINED[vision_model]\n",
    "vision_pretrained = vision_model_config['pretrained_weight']\n",
    "vision_model_type = vision_model_config['vision_model_type']\n",
    "vision_output_dim = vision_model_config['vision_output_dim']\n",
    "data_transform = vision_model_config['data_transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting XRayResizer engine to cv2 could increase performance.\n"
     ]
    }
   ],
   "source": [
    "imsize = 256\n",
    "\n",
    "image_dataset = RSNAImageDataset(\n",
    "    split='train', \n",
    "    transform=data_transform(True, imsize), \n",
    "    phase='classification', \n",
    "    data_pct=1., \n",
    "    imsize=imsize, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.iterable_dataset.IterableDataset at 0x7fb7256d88e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "max_steps = ceil(len(image_dataset) / batch_size)\n",
    "train_dataset = torch2huggingface_dataset(image_dataset, streaming=False)\n",
    "train_dataset.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=8,\n",
    "    collate_fn=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    max_epochs=1,\n",
    "    # max_steps=args.max_steps,\n",
    "    log_every_n_steps=10, \n",
    "    check_val_every_n_epoch=1, \n",
    "    default_root_dir='./trained_models/clf',\n",
    "    callbacks=[StreamingProgressBar(total=max_steps)],\n",
    "    enable_progress_bar=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaptorPipelineWithClassificationHead(\n",
    "    text_model='biobert', \n",
    "    vision_model='resnet-ae', \n",
    "    adaptor_ckpt='/vol/bitbucket/jq619/individual-project/results/resnet-ae_biobert/lightning_logs/version_76005/checkpoints/epoch=29-step=53279.ckpt', \n",
    "    num_classes=2, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | vision_model | _ResNetAE        | 31.1 M\n",
      "1 | text_model   | BertModel        | 108 M \n",
      "2 | adaptor      | Adaptor          | 8.7 M \n",
      "3 | classifier   | Linear           | 1.5 K \n",
      "4 | loss_func    | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------\n",
      "8.7 M     Trainable params\n",
      "139 M     Non-trainable params\n",
      "148 M     Total params\n",
      "592.375   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1168 [00:00<?, ?it/s] "
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
