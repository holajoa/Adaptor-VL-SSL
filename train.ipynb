{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda3\\envs\\idv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from typing import List, Union, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel, AutoModel, ViTImageProcessor\n",
    "\n",
    "import torchxrayvision as xrv\n",
    "from adaptor import Adaptor\n",
    "from utils import load_timm_model, freeze_encoder\n",
    "\n",
    "from image_processor import ae_image_processor, timm_image_processor\n",
    "\n",
    "import skimage\n",
    "\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./weights/ClinicalBERT_checkpoint/ClinicalBERT_pretraining_pytorch_checkpoint were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "text_pretrained_available = [\n",
    "    \"bert-base-uncased\", \n",
    "    \"dmis-lab/biobert-v1.1\", \n",
    "    \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", \n",
    "    \"microsoft/BiomedVLP-CXR-BERT-general\", \n",
    "]\n",
    "\n",
    "### Load vision model\n",
    "# vision_model = xrv.autoencoders.ResNetAE(weights=\"101-elastic\")\n",
    "vision_model = load_timm_model('swin_base_patch4_window7_224', pretrained=True, retain_head=False)\n",
    "\n",
    "### Load text model\n",
    "# text_pretrained = \"microsoft/BiomedVLP-CXR-BERT-general\"\n",
    "text_pretrained = \"./weights/ClinicalBERT_checkpoint/ClinicalBERT_pretraining_pytorch_checkpoint\"\n",
    "text_model = BertModel.from_pretrained(text_pretrained)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_pretrained)\n",
    "image_processor = lambda x: ViTImageProcessor()(x, return_tensors=\"pt\", return_dict=True)\n",
    "\n",
    "### Load sample input\n",
    "img_path = 'sample.jpeg'\n",
    "img = skimage.io.imread(img_path)\n",
    "imgs = np.stack([img, img])\n",
    "vision_inputs = image_processor(imgs)\n",
    "\n",
    "### Define model\n",
    "model = Adaptor(\n",
    "    text_model=text_model,\n",
    "    vision_model=vision_model,\n",
    "    vision_model_type='timm', \n",
    "    vision_output_dim=1024,\n",
    "    projection_dim=768,\n",
    ")\n",
    "\n",
    "### Obtain inputs\n",
    "vision_inputs = image_processor(imgs)\n",
    "text_inputs = tokenizer(\n",
    "    text=[\"Nodule\", \"Lung Lesion\"], \n",
    "    return_tensors=\"pt\", padding=True, \n",
    ")\n",
    "inputs = {**vision_inputs, **text_inputs}\n",
    "\n",
    "### Forward to get output\n",
    "outputs = model(**inputs, return_dict=True, return_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=16,  \n",
    "    num_train_epochs=1, \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, \n",
    "    seed=1117, \n",
    "    push_to_hub=False, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trainer: training requires a train_dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Apps\\Anaconda3\\envs\\idv\\lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1638\u001b[0m )\n",
      "File \u001b[1;32md:\\Apps\\Anaconda3\\envs\\idv\\lib\\site-packages\\transformers\\trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size \u001b[39m=\u001b[39m batch_size\n\u001b[0;32m   1644\u001b[0m \u001b[39m# Data loader and number of training steps\u001b[39;00m\n\u001b[1;32m-> 1645\u001b[0m train_dataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_train_dataloader()\n\u001b[0;32m   1647\u001b[0m \u001b[39m# Setting up training control variables:\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[39m# number of training epochs: num_train_epochs\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m \u001b[39m# number of training steps per epoch: num_update_steps_per_epoch\u001b[39;00m\n\u001b[0;32m   1650\u001b[0m \u001b[39m# total number of training steps to execute: max_steps\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m total_train_batch_size \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mtrain_batch_size \u001b[39m*\u001b[39m args\u001b[39m.\u001b[39mgradient_accumulation_steps \u001b[39m*\u001b[39m args\u001b[39m.\u001b[39mworld_size\n",
      "File \u001b[1;32md:\\Apps\\Anaconda3\\envs\\idv\\lib\\site-packages\\transformers\\trainer.py:854\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[39mReturns the training [`~torch.utils.data.DataLoader`].\u001b[39;00m\n\u001b[0;32m    847\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39mSubclass and override this method if you want to inject some custom behavior.\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 854\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrainer: training requires a train_dataset.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    856\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset\n\u001b[0;32m    857\u001b[0m data_collator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_collator\n",
      "\u001b[1;31mValueError\u001b[0m: Trainer: training requires a train_dataset."
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
